\chapter{Evaluation} \label{ch:Evaluation}

Das entwickelte \ac{mrcpsp}-Framework stellt mit seinen Metaheuristiken und Verfahren für den Umgang von Verspätungen die Basis zur Beantwortung der Forschungsfrage und ihrer Unterfragen dar. Dieses Kapitel nutzt die implementierten Lösungsverfahren und Methodiken und vergleicht diese auf Benchmark-Instanzen. Der Versuchsaufbau wird zunächst im Abschnitt \ref{sec:Versuchsaufbau} erläutert. Unabhängig der Verspätungsszenarien werden im Abschnitt \ref{sec:BenchmarkErgebnisse_MetaheuristischeVerfahren} die Lösungsverfahren auf unterschiedliche Benchmark-Instanzen verglichen, um so die Güte der Verfahren miteinander vergleichen zu können. Die Ergebnisse der proaktiven Methode aus dem Abschnitt \ref{sec:BenchmarkErgebnisse_NaivMethoden} stellen die Referenz für prädiktive und reaktive Methoden dar. Die Ergebnisse der Robustheitsoptimierung als prädiktive Methode werden im Abschnitt \ref{sec:BenchmarkErgebnisse_PraediktiveMethoden} und die Ergebnisse der Neuerzeugung von Zeitplänen zum Unsicherheitszeitpunkt als reaktive Methode im Abschnitt \ref{sec:BenchmarkErgebnisse_ReaktiveMethoden} aufgeführt. Anschließend werden die unterschiedlichen Methoden im Abschnitt \ref{sec:BenchmarkVergleich} miteinander verglichen. 


\section{Versuchsaufbau} \label{sec:Versuchsaufbau}

Der Versuchsaufbau erstreckt sich über die verschiedenen Experimente, welche bereits in der Umsetzung im Abschnitt \ref{sec:Experimente} erläutert wurden. Die Auswahl der Benchmark-Instanzsets wurde im Abschnitt \ref{sec:Benchmarkdatensatz} getroffen. Für die Evaluierung sind die Instanzsets m1, m2, n0, n1 und exklusiv für den Vergleich der Lösungsverfahren j20 der PSPLIB vorgesehen. \\

Die Ausführung der Experimente wurde auf zwei Computersystemen verteilt ausgeführt. Maßgeblich für die Ausführungsgeschwindigkeit ist die Prozessorleistung. Das erste System stellt ein Desktop-PC mit einem Intel\textsuperscript{\textregistered} Core\texttrademark \, i7-8700K mit 6 Kernen und 12 Threads als Prozessor dar. Das zweite System ist ein virtueller Server, welcher als Prozessor einen Intel\textsuperscript{\textregistered} Xeon\textsuperscript{\textregistered} E5-2680 v3 vorsieht, wobei von den 24 theoretischen Kernen nur 6 zur Verfügung stehen. Für den virtuellen Server lief das Bash-Startskript aus Anhang \ref{ch:Anhang} im Hintergrundmodus. 

Für die Parametrisierung der Experimente sind eine Liste von Iterationen, die Anzahl der Experimente je Solver/Iteration-Kombination und je nachdem eine Robustheitsmessung vorgesehen (vgl. Abschnitt \ref{subsec:VergleichLösungsansätze} und \ref{subsec:VergleichUnsicherheiten}).  \\

In der Literatur werden unterschiedliche Listen von Iterationen je Forschungsgegenstand verwendet. Bei dem Lösungsvariantenvergleich sind in der Literatur von \cite[S. 16]{kolisch_psplib_1997} für das (Basis) \ac{rcpsp} 1 000 und 5 000 Iterationen vorgesehen, bei \cite[S. 148]{jozefowska_simulated_2001} ist die Menge höher, nämlich 100, 500, 1 000, 5 000, 10 000, 20 000, 50 000 und 100 000, wobei in einigen Instanzsets eine Sättigung zwischen 10 000 - 20 000 Iterationen zu erkennen ist. \cite[S. 612]{wuliang_improved_2014} vergleicht die Ergebnisse verschiedener Varianten zwischen 4 000 und 6 000 Iterationen. Im Rahmen dieser Evaluierung ist somit für das Finden der (Basis-)Zeitpläne eine Liste mit 5 00, 1 000, 2 500 und 5 000 Iterationen vorgesehen. \\

Um die Qualität eines Solvers besser bestimmen zu können, werden diese je nach vorgesehener Iteration mehrfach ausgeführt und die Ergebnisse gemittelt. Die mehrfache Ausführung geschieht im Prozessor parallel (vgl. Abschnitt \ref{subsec:VergleichLösungsansätze}). In dieser Arbeit richtet sich die Anzahl der Wiederholungen nach der Menge der Rechenkerne. Hierfür wird das zweite System als Referenz verwendet und somit $n = 6$ festgelegt. Dies führt dazu, dass jeder Solver für jede Iteration sechsmal ausgeführt wird. \\

Eine Robustheitsfunktion $\Omega$ wird für den Vergleich der implementierten Lösungs-verfahren und der prädiktiven Methoden benötigt. Für den Vergleich der implementierten Lösungsverfahren wird nur die Summe der freien Puffer innerhalb eines Zeitplans betrachtet, welche über die Funktion $\Omega^{SF1}$ im Abschnitt \ref{subsec:Praediktive_Methoden} definiert ist. Die Auswahl der Robustheitsfunktion $\Omega$ für den Unsicherheitsvergleich geschieht über ein seperates Experiment, welches im Abschnitt \ref{sec:BenchmarkErgebnisse_PraediktiveMethoden} behandelt wird. \\

Im Anhang \ref{ch:Auswertungen} sind die Ergebnisse festgehalten. Durch die Vielzahl der Instanzsets wird für die Evaluierung der Fokus vermehrt auf das Set n1 festgelegt, welches eine moderate Komplexität gegenüber den anderen Instanzsets (m1, m2 und n0) aufweist. Diese gilt es dennoch in der Evaluierung zu berücksichtigen. 
